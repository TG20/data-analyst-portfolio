{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bike Rentals\n",
    "\n",
    "This notebook tries to predict the total number of bike rentals per hour on a single day using the dataset compiled by Hadi Fanaee-T. You can download it from the [University of California, Irvine's website](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bike_rental = pd.read_csv(\"data-sets/bike_rental_hour.csv\")\n",
    "bike_rental.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD8CAYAAABZ/vJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJwaIJKkTA0SS1IkBIknq5P8DV+WS7LwxOl8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f763c128780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a histrogram of the cnt column\n",
    "#to take a look of the distribution of total rentals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(bike_rental[\"cnt\"])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rental.corr()[\"cnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''We created the \"time label\" feature engineering converting \n",
    "   the 24-hour format into four 6-hour groups'''\n",
    "\n",
    "def assign_label(hour):\n",
    "    #Assigns labels based on hours\n",
    "    #1- Morning, 2- Afternoon, 3- Evening, 4- Night\n",
    "    if hour >= 0 and hour < 6:\n",
    "        return 4\n",
    "    elif hour >= 6 and hour < 12:\n",
    "        return 1\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 2\n",
    "    elif hour >= 18 and hour <= 24:\n",
    "        return 3\n",
    "\n",
    "bike_rental[\"time_label\"] = bike_rental[\"hr\"].apply(assign_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on a metric\n",
    "\n",
    "Before training our model, we will split the data into train and test sets. We will use columns within the data to generate a list of features for our target label and drop the unneeded ones.   \n",
    "\n",
    "We will use the regression metric, mean squared error since we are making predictions on variables that are numeric and continuous. With the train and test sets created, the linear regression model will be created, trained, and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "#create train and test set\n",
    "train = bike_rental.sample(frac=.8)\n",
    "test = bike_rental.loc[~bike_rental.index.isin(train.index)]\n",
    "\n",
    "#arrange the columns we want for regression\n",
    "predict_list = list(train.columns)\n",
    "remove_cols = {\"cnt\", \"dteday\", \"casual\", \"registered\"}\n",
    "predict_list = [train_cols for train_cols in predict_list if train_cols not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 18170.074692270962\n",
      "Root Squared Error: 134.79641943416362\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(train[predict_list], train[\"cnt\"])\n",
    "predictions = model.predict(test[predict_list])\n",
    "mse = np.mean((predictions - test[\"cnt\"]) ** 2)\n",
    "rmse = mse ** .5\n",
    "print(\"Mean Squared Error: {0}\".format(mse))\n",
    "print(\"Root Squared Error: {0}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "The error value is high compared to the prediction values. The dataset has a few exceptionally high bike rentals. The MSE computes these values and penalizes them leading to a higher score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "\n",
    "Both train and test sets applied to the Decision Tree to see if it is more accurate compared to the Linear model. After training and testing the initial model, we will use another Decision Tree model and tweak its hyperparameters to gauge for more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Results\n",
      "Mean Squared Error: 3131.186996547756\n",
      "Root Squared Error: 55.957010253834646\n",
      "\n",
      "\n",
      "Tweaked Decision Tree Regression Results\n",
      "Mean Squared Error: 2844.7562939570257\n",
      "Root Squared Error: 53.33625684238655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#create a decision tree model, train and test it\n",
    "regression = DecisionTreeRegressor()\n",
    "regression.fit(train[predict_list], train[\"cnt\"])\n",
    "predict = regression.predict(test[predict_list])\n",
    "mse = np.mean((predict - test[\"cnt\"]) ** 2)\n",
    "rmse = mse ** .5\n",
    "\n",
    "print(\"Decision Tree Regression Results\")\n",
    "print(\"Mean Squared Error: {0}\".format(mse))\n",
    "print(\"Root Squared Error: {0}\".format(rmse))\n",
    "print(\"\\n\")\n",
    "\n",
    "#tweak model to improve accuracy\n",
    "regression = DecisionTreeRegressor(min_samples_leaf=15, max_depth=20)\n",
    "regression.fit(train[predict_list], train[\"cnt\"])\n",
    "predict = regression.predict(test[predict_list])\n",
    "mse = np.mean((predict - test[\"cnt\"]) ** 2)\n",
    "rmse = mse ** .5\n",
    "\n",
    "print(\"Tweaked Decision Tree Regression Results\")\n",
    "print(\"Mean Squared Error: {0}\".format(mse))\n",
    "print(\"Root Squared Error: {0}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings - Decision Tree Error\n",
    "The decision tree seems to be more reliable in estimating predictions compared to the linear model due to the model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "\n",
    "Similar to the model above, we will train and test the data to the Random Forest model in hopes to get a more accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Results\n",
      "Mean Squared Error: 1746.537839470652\n",
      "Root Squared Error: 41.79160010660817\n",
      "\n",
      "\n",
      "Tweaked Random Forest Regression Results\n",
      "Mean Squared Error: 2452.4316511041343\n",
      "Root Squared Error: 49.52203197672864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#create a random forest model, train and test it\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train[predict_list], train[\"cnt\"])\n",
    "predict = rf.predict(test[predict_list])\n",
    "mse = np.mean((predict - test[\"cnt\"]) ** 2)\n",
    "rmse = mse ** .5\n",
    "\n",
    "print(\"Random Forest Regression Results\")\n",
    "print(\"Mean Squared Error: {0}\".format(mse))\n",
    "print(\"Root Squared Error: {0}\".format(rmse))\n",
    "print(\"\\n\")\n",
    "\n",
    "#tweak model hoping to get a more accurate prediction\n",
    "rf = RandomForestRegressor(min_samples_leaf=5, max_depth=10)\n",
    "rf.fit(train[predict_list], train[\"cnt\"])\n",
    "predict = rf.predict(test[predict_list])\n",
    "mse = np.mean((predict - test[\"cnt\"]) ** 2)\n",
    "rmse = mse ** .5\n",
    "\n",
    "print(\"Tweaked Random Forest Regression Results\")\n",
    "print(\"Mean Squared Error: {0}\".format(mse))\n",
    "print(\"Root Squared Error: {0}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings - Random Forest Error\n",
    "\n",
    "The random forest model improved the accuracy immensely in comparison to the decision tree model by removing some sources of overfitting. However, tweaking the model led to a more unfortunate outcome. More time could be spent tuning the hyperparameters to increase the model's accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
